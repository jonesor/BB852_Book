# Distributions and summarising data

This chapter covers two broad topics: the concept of statistical distributions and summarising data. It ends with a brief look at the "law of large numbers".

## Distributions

A statistical distribution is a description of the relative number of times (the *frequency*) possible outcomes will occur if repeated samples were to be taken. They are important because (1) they are useful descriptors of data and (2) they form the basis for assumptions in some statistical approaches. For example, statistical analyses often assume a normal distribution. The normal distribution is symmetrical (centered on the mean) and 68% of observations fall within 1 standard deviation (s.d.), and 95% of observations fall within 2 s.d..

```{r echo = FALSE, fig.height=3, fig.width = 4,fig.align='center'}
normData <- data.frame(x = seq(-3,3,0.1)) %>% 
  mutate(dens = dnorm(x ,mean = 0, sd=1)) %>%
  mutate(sd1 = ifelse(x <= 1 & x >= -1,TRUE,FALSE)) %>%
  mutate(sd2 = ifelse(x <= 2 & x >= -2,TRUE,FALSE))

ggplot(normData,aes(x=x,y=dens))+
  geom_line() + 
  geom_ribbon(data = normData %>% filter(sd2 == TRUE),
              aes(x = x, ymax = dens, ymin = 0),fill = '#00517f') +
  geom_ribbon(data = normData %>% filter(sd1 == TRUE),
              aes(x = x, ymax = dens, ymin = 0),fill = '#0072B2') +
  geom_line()+
  geom_segment(aes(x = -1, xend = 1,
                   y = .22, yend = .22), 
               colour = "#FFFFFF", size = 1.5) +
  geom_label(aes(label = '1 SD: 68%', x = 0, y = .22), 
             colour = 'gray10', fill = '#FFFFFF') +
  geom_segment(aes(x = -2, xend = 2,
                   y = 0.05, yend = 0.05), 
               colour = "#FFFFFF", size = 1.5) +
  geom_label(aes(label = '2 SD: 95%', x = 0, y = 0.05), 
             colour = 'gray10', fill = '#FFFFFF') +
  xlab("Standard deviation (SD)") + 
  ylab("Density") +
  scale_x_continuous(breaks = seq(from = -4, to = 4, by = 1))+
  theme_minimal() +
  ggtitle("The normal distribution")
  
```


We will use R to simulate some distributions, and explore these to get a feel for them.
R has functions for generating random numbers from different kinds of distributions. For example, the function `rnorm` will generate numbers from a normal distribution and `rpois` will generate numbers from a Poisson distribution.

## Normal distribution

The `rnorm` function has three arguments. The first argument is simply the number of values you want to generate. Then, the second and third arguments specify the the mean and standard deviation values of the distribution (i.e. where the distribution is centered and how spread out it is).

The following command will produce 6 numbers from a distribution with a mean value of 5 and a standard deviation of 2. 

```{r, echo = FALSE}
set.seed(3542)
```

```{r}
rnorm(6,5,2)
```

```{block, type="do-something"}
Try changing the values of the arguments to alter the number of values you generate, and to alter the mean and standard deviation.
```

Let's use this to generate a larger data frame, and then place markers for the various measures of "spread" onto a plot. *Note that here I put a set of parentheses around the plot code to both display the result AND save the plot as an R object called `p1`*

```{r, message=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
rn <- data.frame(d1 = rnorm(500,5,2))
summary(rn) #Take a look

#Plot the data
(p1 <- ggplot(rn,aes(x=d1)) + 
  geom_histogram()
  )
```

We can calculate the mean and standard deviation using `summarise` (along with other estimates of "spread"). The mean and standard deviation values will be close (but not identical) to the values you set when you generated the distribution. 

*Note that here I put a set of parentheses around the code to both display the result AND save the result in an object called `sv`*

```{r, message=FALSE}
(sv <- rn %>% 
  summarise(meanEst = mean(d1),
            sdEst = sd(d1),
            varEst = var(d1),
            semEst = sd(d1)/sqrt(n()))
 )
```

Let's use the function `geom_vline` to add some markers to the plot from above to show these values...

```{r, message=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
(p2 <- p1 + 
  geom_vline(xintercept = sv$meanEst, size=2) + #mean
  geom_vline(xintercept = sv$meanEst+sv$sdEst, size=1) + #upperSD
  geom_vline(xintercept = sv$meanEst-sv$sdEst, size=1) #lowerSD
)
```

We can compare these with the true values (the values we set when we generated the data), by adding them to the plot in a different colour (mean=5, sd=2).

```{r, message=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
(p3 <- p2 + 
  geom_vline(xintercept = 5, size=2, colour="red") + #mean
  geom_vline(xintercept = 5+2, size=1,colour="red") + #upperSD
  geom_vline(xintercept = 5-2, size=1,colour="red") #lowerSD
 ) 

```

```{block, type="do-something"}
Try repeating these plots with data that has different sample sizes. For example, use sample sizes of 5000, 250, 100, 50, 10. What do you notice? You should notice that for smaller sample sizes, the true distribution is not captured very well.
```

When you calculate the mean and standard deviation, you are actually fitting a simple model: the mean and standard deviation are parameters of the model, which assumes that the data follow a normal distribution.



```{block, type="do-something"}
Try adding lines for the standard error of the mean to one of your histograms.
```


## Comparing normal distributions

Because normal distributions all have the same shape, it can be hard to grasp the effect of changing the distribution's parameters viewing them in isolation. In this section you will write some code to compare two normal distributions. This approach can be useful when considering whether a proposed experiment will successfully detect a difference between treatment groups. We'll look at this topic, known as "power analysis", in greater detail in a later class. For now we will simply use `ggplot` to get a better feel for the normal distribution.

Let's use `rnorm` to generate a larger data frame with two sets of numbers from different distributions: (d1: mean = 5, sd = 2; d2: mean = 8, sd = 1). 

```{r, message=FALSE}
rn <- data.frame(d1 = rnorm(500,5,2),d2 = rnorm(500,8,1))
summary(rn)
```

The summaries (above) show that the mean and the width of the distributions vary, but we should always plot our data. So lets make a plot in `ggplot`. In the dataset I created I have the data arranged by columns side-by-side, but `ggplot` needs the values to be arranged in a single column, and the identifier of the sample ID in a second column. I can use the function `pivot_longer` to rearrange the data into the required format.

```{r,message=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
rn <- pivot_longer(rn,cols= c(d1,d2), names_to = "sampleID", values_to = "value") #rearrange data

#Plot histograms using "identity", and make them transparent
ggplot(rn,aes(x = value,fill=sampleID)) +
  geom_histogram(position = "identity", alpha=0.5)
```


```{block, type="do-something"}
Try changing the distributions and re-plotting them (you can change the number of samples, the mean values and the standard deviations).
```

## Poisson distribution

The Poisson distribution is typically used when dealing with count data. The values must be whole numbers (integers) and they cannot be negative. The shape of the distributions varies with the "`lambda`" parameter. Small values of lambda give more skewed distributions.

```{r, echo=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
poissonData <- data.frame(x = seq(0,10,1)) %>% 
  mutate(dens = dpois(x ,lambda = 2))

L2 <- ggplot(poissonData,aes(x = x,y = dens)) + 
  geom_point() + 
  geom_segment( aes(x=x, xend=x, y=0, yend=dens)) +
  scale_x_continuous(breaks = 0:10)+
  xlab("x") + 
  ylab("Density") + 
  theme_minimal()

poissonData <- data.frame(x = seq(0,10,1)) %>% 
  mutate(dens = dpois(x ,lambda = 5))

L5 <- ggplot(poissonData,aes(x = x,y = dens)) + 
  geom_point() + 
  geom_segment( aes(x=x, xend=x, y=0, yend=dens)) +
  scale_x_continuous(breaks = 0:10)+
  xlab("x") + 
  ylab("Density") +
  theme_minimal()

L2+ggtitle("lambda = 2")+L5 + ggtitle("lambda = 5")

```


Let's generate and plot some Poisson distributed data.


```{r, message=FALSE, fig.height=3, fig.width = 4,fig.align='center'}
rp <- data.frame(d1 = rpois(500,2.4))
summary(rp) #Take a look

#Plot the data
(p1 <- ggplot(rp,aes(x=d1)) + 
  geom_histogram(binwidth = 1) # we know the bins will be 1
  )
```


```{block, type="do-something"}
Try changing the value of lambda and look at how the shape changes.
```

Let's calculate summary statistics of mean and standard deviation for this distribution

```{r, message=FALSE}
(sv <- rp %>% 
  summarise(meanEst = mean(d1),
            sdEst = sd(d1))
 )
```
Now lets plot the mean and the 2 times the standard deviation on the graph. Remember that for the normal distribution (above) that 95% of the data were within 2 times the standard deviation.

```{r, fig.height=3, fig.width = 4,fig.align='center'}
p1 + 
  geom_vline(xintercept = sv$meanEst, size=2) + #mean
  geom_vline(xintercept = sv$meanEst+2*sv$sdEst, size=1) + #upper2SD
  geom_vline(xintercept = sv$meanEst-2*sv$sdEst, size=1) #lower2SD

```

This looks like a TERRIBLE fit: The mean is not close to the most common value in the data set and the lower limit of the standard deviation indicates we should expect some negative values - this is impossible for Poisson data. The reason for this is that mean and standard deviation, and therefore standard error, are intended for normally distributed data. When the data come from other distributions we must take another approach.

So how should we summarise this data?

One approach is to report the median as a measure of "central tendency" instead of the mean, and to report "quantiles" of the data along with the range (i.e. minimum and maximum). Quantiles are simply the cut points that divide the data into parts. For example, the 25% quantile is the point where (if the data were arranged in order) one quarter of the values would fall below; the 50% quantile would mark the middle of the data (= the median); the 75% quantile would be the point when three-quarters of the data are below. You can calculate those things using `dplyr`'s `summarise`. However, you can also simply use the base R `summary` command.

```{r}
(sv <- rp %>% 
  summarise(minVal = min(d1),
            q25 = quantile(d1,0.25),
            med = median(d1),
            q75 = quantile(d1,0.75),
            maxVal = max(d1))
 )

#base R summary is just as good.
summary(rp$d1)
```

## Comparing normal and Poisson distributions

To get a better feel for how these two distributions differ, lets use the same approach we used above to plot two distributions together.

```{r,fig.height=3, fig.width = 4,fig.align='center'}
rn <- data.frame(normDist = rnorm(500,2,2),poisDist = rpois(500,2.4))
summary(rn)

rn <- pivot_longer(rn,cols= c(d1,d2), names_to = "sampleID", values_to = "value") #rearrange data

#Plot histograms using "identity", and make them transparent
ggplot(rn,aes(x = value,fill=sampleID)) +
  geom_histogram(position = "identity", alpha=0.5,binwidth = 1)
```

```{block, type="do-something"}
Try changing the arguments in the `rnorm` and `rpois` commands to change the distributions. 
```
 

Finally, let's take another view of these data and look at them using box plots. Box plots are a handy alternative to histograms and many people prefer them.

```{r,fig.height=3, fig.width = 4,fig.align='center'}
ggplot(rn,aes(x=sampleID, y = value,fill=sampleID)) +
  geom_boxplot()
```

You should see the main features of both distributions are captured pretty well. The normal distribution is approximately symmetrical and the Poisson distribution is skewed (one whisker longer then the other) and cannot be <0. Which graph to you prefer? (there's no right answer!)




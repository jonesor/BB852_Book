[["question-3-habitat-restoration.html", "Chapter 29 Question 3: Habitat restoration 29.1 a) 29.2 b)", " Chapter 29 Question 3: Habitat restoration The aim of this question was to test the hypothesis that habitat restoration leads to an increase in the average body mass of a specific bird species. I hypothesize that restored habitats may support healthier bird populations, reflected in larger body mass. The form of the expected data lends itself to a t-test. So I will use that method. 29.1 a) First I will import the data to examine it. restoration &lt;- read.csv(&quot;DataSetLibrary/habitat_restoration.csv&quot;) summary(restoration) ## BodySize ## Min. : 88.0 ## 1st Qu.:135.8 ## Median :146.0 ## Mean :146.0 ## 3rd Qu.:160.2 ## Max. :185.0 I can see that the data set is just one column of data called BodySize. I can get the mean and standard deviation in a couple of ways. For example like this: mean(restoration$BodySize) ## [1] 146.0319 sd(restoration$BodySize) ## [1] 18.42358 Or using dplyr like this: (dataSummary &lt;- restoration %&gt;% summarise(meanVal = mean(BodySize), sdVal = sd(BodySize))) ## meanVal sdVal ## 1 146.0319 18.42358 29.2 b) I now conduct a power analysis to get the required sample size for 80% power. controlMean &lt;- dataSummary$meanVal treatmentMean &lt;- controlMean * 1.2 # A 20% increase compared to the control sdValue &lt;- dataSummary$sdVal sampleSize &lt;- 10 # I&#39;ll start with a small sample size and see what happens! I can then simulate a t-test using t.test and use replicate to repeat the simulation any number of times. nReps &lt;- 1000 powerResults &lt;- replicate( nReps, t.test( rnorm(sampleSize, controlMean, sdValue), rnorm(sampleSize, treatmentMean, sdValue) )$p.value ) I then can ask how many of the 1000 replicates produced statistically significant p-values (i.e. &lt; 0.05). sum(powerResults &lt; 0.05) ## [1] 913 The power is given as a percentage like this: (sum(powerResults &lt; 0.05) / nReps) * 100 ## [1] 91.3 Therefore, in this case, it looks like I can get away with a smaller sample size. 29.2.1 Advanced level Rather than looking individually at different sample size, I could look systematically at how power changes with sample size like this: # Set up a data frame for the simulation results simulData &lt;- data.frame(sampleSize = 2:20) # Set basic values controlMean &lt;- dataSummary$meanVal treatmentMean &lt;- controlMean * 1.2 # A 20% increase compared to the control sdValue &lt;- dataSummary$sdVal # Function to do the t-test pwr &lt;- function(n) { sum(replicate( 1000, t.test( rnorm(n, controlMean, sdValue), rnorm(n, treatmentMean, sdValue) )$p.value ) &lt; 0.05) / 1000 } # map_dbl applying the function for every value of # simulData$sampleSize simulData$Power &lt;- purrr::map_dbl(simulData$sampleSize, pwr) Then plot the results… # Plot the output ggplot(simulData, aes(x = sampleSize, y = Power)) + geom_point() + geom_line() + geom_hline(yintercept = 0.8, linetype = &quot;dashed&quot;) I could then read of the graph, the best sample size for any desired power level. I could also adjust the “alpha value”, i.e. the significance threshold, so that it is more strict. For example I could change from 0.05 to 0.01 for a more convincing study. "]]

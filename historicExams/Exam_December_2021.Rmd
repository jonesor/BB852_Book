# Exam 2021


```{block, type="do-something"}

This exam includes four questions that test different aspects of your learning during this course: data wrangling, data visualisation and statistics. Each question is broken down into a number sub-questions. 

Your work should be handed in as a single PDF. 

The number of each question should be clearly indicated, and the answers to each question should start on a new page.

For each question you must provide the R code you used to answer the question. The code should include comments to explain what you are doing. The code should be provided as text using a fixed-width font such as `Courier`. The rest of your answers should be in another font (e.g. Times New Roman, Cambria). Please use *text* rather than a screenshot of your code.


* Plots and tables should have appropriate captions. 
* Plots should be produced using `ggplot`.
* Remember that you can make "panels" of plots (e.g. Fig 1A, B) using the package `patchwork`.
* Axis labels are important. Sometimes you may want to edit them to be different from a data column name.
* Reporting of any statistics should be appropriate to the type of analysis you have done. There are examples in the course materials.
* Reporting of methods and results should be written in the style of a scientific paper (again, there are examples in the course materials).

*If you don't understand any aspects of the questions, please ask for help!*

**Hand in deadline is 7th January 2022 at 12:00 CET (noon)**

**You MUST submit your work via itsLearning (not email!) Instructions for this will follow.**
```

```{r,echo=FALSE,message=FALSE}
library(tidyverse)
library(ggfortify)

options(dplyr.summarise.inform = FALSE)
```

*****

## 1) Moths and butterflies (10 points)


The dataset `lepi.csv` is a subset of Lepidoptera (moths and butterflies) species occurrence data for Denmark held by the Global Biodiversity Information Facility (GBIF) ([https://www.gbif.org](https://www.gbif.org)). It includes columns for taxonomy, geographic location, and time. The column called `dayOfYear` is the numeric day of the year (i.e. January 1st is day 1).

a) Identify the five most commonest species in the dataset and filter the data to just these species. 

Next, make a two panel plot with two graphs side-by-side. For plot A, make a graph with points joined by lines, that shows the yearly number of observations. The x-axis should be the year and the y-axis should be the number of observations (for all 5 species combined).

For plot B, make a single graph showing the number of observations per year for each of these species. Year should be on the horizontal axis, and number of observations should be on the vertical axis. Each species should be represented by a line with points (i.e. there should be five lines, each with a different colour).

b) Produce a table showing the minimum, maximum, mean and standard deviation of the number of observations per year for each species. i.e. column 1 should be species, column 2-5 should be min, max, mean and standard deviation. Arrange the data in descending order of mean number of observations (i.e. largest number first).

```{r echo = FALSE}
# Prepare data
allmoth <- read.csv("/Users/jones/Dropbox/Moths/GBIFmoths/allData.csv")
names(allmoth)

lepi <- allmoth %>%
  select(species, year, month, day, decimalLatitude, decimalLongitude) %>%
  mutate(dayOfYear = lubridate::yday(lubridate::dmy(paste(day, month, year, sep = "/")))) %>%
  filter(year %in% 2000:2010)

write.csv(lepi, file = "CourseData/lepi.csv", row.names = FALSE)
```

```{r echo = FALSE, eval = FALSE}
library(patchwork)

# ID the most common
top5 <- lepi %>%
  group_by(species) %>%
  summarise(number = n()) %>%
  arrange(-number) %>%
  slice(1:5) %>%
  pull(species)


lepi1 <- lepi %>%
  filter(species %in% top5) %>%
  ungroup() %>%
  group_by(year) %>%
  summarise(number = n())

A <- ggplot(lepi1, aes(x = year, y = number)) +
  geom_line() +
  geom_point()

lepi2 <- lepi %>%
  filter(species %in% top5) %>%
  group_by(species, year) %>%
  summarise(number = n())

B <- ggplot(lepi2, aes(x = year, y = number, colour = species)) +
  geom_line() +
  geom_point()

A + ggtitle("A") + B + ggtitle("B")


lepi2 %>%
  group_by(species) %>%
  summarise(min = min(number), max = max(number), mean = mean(number), sd = sd(number)) %>%
  arrange(-mean)
```



## 2) Home range size (10 points)

The home range size of great tits was assessed in two areas of woodland has been recorded to range between 0.06 to 14 hectares. This large variation may be influenced by the environment. To test this idea, researchers estimated the range size of birds from two different environments (1) mature broadleaf woodland, which is thought to be the best habitat for these birds and (2) pine plantation forest, which is thought to be inferior habitat. The hypothesis is that birds in poorer habitat need to have bigger home ranges in order to survive.

Test this hypothesis using the dataset `birdRangeSize.csv`

```{r echo = FALSE}
set.seed(123)
birdRangeSize <- data.frame(
  birdID = 1:30,
  habitat = rep(c("Broadleaf", "Pine"), each = 15)
) %>%
  mutate(rangeSize = round(c(rnorm(15, 4, 2), rnorm(15, 7, 3)), 3))
birdRangeSize
write.csv(birdRangeSize, file = "CourseData/birdRangeSize.csv", row.names = FALSE)
set.seed(Sys.time())
```




a) plot the data using a boxplot and overlaid jittered points.

```{r echo = FALSE, eval = FALSE}
ggplot(birdRangeSize, aes(x = habitat, y = rangeSize)) +
  geom_boxplot() +
  geom_jitter()
```


b) carry out a randomisation test to determine if there is a significant difference in the range size in the two habitats. Write (i) a brief method description and (ii) a summary of the results. 

```{r echo = FALSE, eval=FALSE}
observedDiff <- birdRangeSize %>%
  group_by(habitat) %>% # group the data by treatment
  summarise(mean = mean(rangeSize)) %>% # calculate means
  pull(mean) %>% # extract the mean vector
  diff()

shuffledData <- data.frame(rep = 1:1000) %>%
  mutate(shuffledDiffs = replicate(
    1000,
    birdRangeSize %>%
      mutate(habitat = sample(habitat)) %>%
      group_by(habitat) %>%
      summarise(mean = mean(rangeSize)) %>%
      pull(mean) %>%
      diff()
  ))

(p1 <- ggplot(shuffledData, aes(x = shuffledDiffs)) +
  geom_histogram() +
  theme_minimal() +
  xlab("Difference") +
  geom_vline(xintercept = observedDiff)
)

(trialResult <- table(shuffledData$shuffledDiffs >= observedDiff))
trialResult[2] / 1000

# Write up as shown here: [https://jonesor.github.io/BB852_Book/randomisation-tests.html#writing-it-up](https://jonesor.github.io/BB852_Book/randomisation-tests.html#writing-it-up)
```


##  3) Power in a field study (10 points)


Running speed is a key attribute of escape behaviour.  Golden-mantled ground squirrels (*Spermophilus lateralis*) and least chipmunks (*Tamias minimus*) live together on the mountains of North America. It has been hypothesised that the ground squirrels can utilise more habitat area than least chipmunks they are faster, and can therefore use areas that are more exposed to predation (they would be able to run away quicker). 

Your colleague studies one of these species, ground squirrels, and has measured running speed for a small number of individuals in this species only. She has sent you the data as a file called `runningSquirrels.csv`. 

You would like to test the hypothesis that the least chipmunks are slower than ground squirrels. You decide that a speed difference of 20% would be biologically meaningful. However, due to current travel restrictions you cannot go to the field site in Colorado, USA yourself. Instead, you must instruct a research assistant at the site to measure running speed in the chipmunks. They need to know how many of each species to measure.

Use the pilot study data to conduct a power analysis to help plan your study.


```{r echo = FALSE, eval = TRUE}
set.seed(23)
ss <- 8
runningSquirrels <- data.frame(tagNumber = sample(100:500, size = ss)) %>%
  mutate(speed = round(rnorm(ss, 3.14, 1), 3))
write.csv(runningSquirrels, file = "CourseData/runningSquirrels.csv", row.names = FALSE)
set.seed(Sys.time())
```


a) Summarise the pilot study data to obtain mean and standard deviation.

b) Conduct a power analysis based on the pilot study data to estimate the number of samples required to carry out your experiment with 80% power. Describe the results of this power analysis.

```{r echo = FALSE, eval = FALSE}
groundSquirrelMean <- mean(runningSquirrels$speed)
groundSquirrelSD <- sd(runningSquirrels$speed)

sampleSize <- 35

powerResults <- replicate(
  1000,
  t.test(
    rnorm(sampleSize, groundSquirrelMean, groundSquirrelSD),
    rnorm(sampleSize, groundSquirrelMean * 1.2, groundSquirrelSD)
  )$p.value
)
sum(powerResults < 0.05) / 1000
```




## 4) Mussels (20 points)

Freshwater mussels are benthic macroinvertebrates that are important keystone species in many areas, They burrow into sediment and feed by filtering suspended particles from the water. They are globally threatened, with declines lined to habitat modification, pollution and invasive species impacts.

Surveys were carried out in the Danube Basin (Czech Republic) to examine the abundance of swan mussel (*Anodonta cygnea*) in relation to water depth and substrate type (mud, sand, or gravel). Mussels were counted from 1$m^2$ quadrats. The data are available in the file `musselSurvey.csv`.

Use an appropriate statistical model to explore the relationship between water depth and mussel density. Does this relationship differ depending on habitat type?

a) Plot the data to show the relationship between the the mussel density and water depth. Colour code the points by habitat type.

b) Fit a suitable statistical model to estimate the statistical relationship between water depth, habitat type, and mussel density. Describe the method and then summarise the results produced by the model as if you were writing a report/thesis. Include a statement about what proportion of variance in mussel density is explained by the model, and the relative importance of the explanatory variables in the model.

c) Produce a plot that shows (in addition to the raw data points) the fitted values produced by your model and the uncertainty in those estimates. 


```{r echo = FALSE, eval =TRUE}
# Simulate data.
set.seed(123)
ss <- 50

df1 <- data.frame(
  habitat = "gravel",
  depth = round(runif(ss, 0, 3), 2)
) %>%
  mutate(nMussels = rpois(ss, exp(0.1 + 0.00001 * depth)))

df2 <- data.frame(
  habitat = "mud",
  depth = round(runif(ss, 0, 3), 2)
) %>%
  mutate(nMussels = rpois(ss, exp(0.0 + 0.8 * depth)))

df3 <- data.frame(
  habitat = "sand",
  depth = round(runif(ss, 0, 3), 2)
) %>%
  mutate(nMussels = rpois(ss, exp(0.0 + 0.6 * depth)))

musselSurvey <- bind_rows(df1, df2, df3)

ggplot(musselSurvey, aes(x = depth, y = nMussels, colour = habitat)) +
  geom_point()

write.csv(musselSurvey, file = "CourseData/musselSurvey.csv", row.names = FALSE)
set.seed(Sys.time())
```
